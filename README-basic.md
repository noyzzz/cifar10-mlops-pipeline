# ğŸ“ Workshop: Basic CIFAR-10 Training

**Simple PyTorch training - No MLOps yet!**

This branch demonstrates a basic ML workflow **without** MLOps practices.

## ğŸ“ What's Here?

```
â”œâ”€â”€ model.py       # Simple CNN definition
â”œâ”€â”€ train.py       # Basic training script
â”œâ”€â”€ predict.py     # CLI prediction tool
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

### 1. Install dependencies

```bash
pip install torch torchvision pillow
```

### 2. Train the model

```bash
python train.py
```

**Output:**
```
Using device: cpu
Loading CIFAR-10 dataset...
Train samples: 50000
Test samples: 10000

Starting training for 20 epochs...

Epoch [1/20]
  Batch [100/391] Loss: 1.8234 Acc: 32.45%
  ...
  Train Loss: 1.6543 | Train Acc: 40.23%
  Test Loss:  1.4321 | Test Acc:  48.56%
  âœ… Saved best model (accuracy: 48.56%)

...

Training completed! Best test accuracy: 72.34%
Model saved to: best_model.pt
Classes saved to: classes.txt
```

### 3. Make predictions

```bash
python predict.py cat.jpg
```

**Output:**
```
Loading model...
Loading image: cat.jpg
Making prediction...

========================================
Prediction: cat
Confidence: 78.45%
========================================
```

## âŒ Problems with This Approach

This basic workflow has **serious limitations**:

### 1. ğŸ“‰ **No Experiment Tracking**
- âŒ Can't compare different runs
- âŒ Don't know which hyperparameters worked best
- âŒ No way to reproduce exact results
- âŒ Metrics are lost after terminal closes

### 2. ğŸ”„ **No Model Versioning**
- âŒ Overwrites `best_model.pt` every time
- âŒ Can't rollback to previous versions
- âŒ Lost track of model history
- âŒ No way to compare models

### 3. ğŸš€ **No Deployment Strategy**
- âŒ Just a `.pt` file - how to serve it?
- âŒ No API for applications to use
- âŒ Can't integrate with production systems
- âŒ Manual predictions only

### 4. ğŸ”¬ **No Reproducibility**
- âŒ Different results on different machines
- âŒ No containerization
- âŒ Dependency conflicts
- âŒ "Works on my machine" syndrome

### 5. ğŸ¤¦ **Everything is Manual**
- âŒ Manual testing
- âŒ Manual deployment
- âŒ No automation
- âŒ No CI/CD

### 6. ğŸ› **No Quality Assurance**
- âŒ No automated tests
- âŒ No validation pipeline
- âŒ Easy to introduce bugs
- âŒ No code quality checks

## â¡ï¸ Next Steps

See how MLOps solves these problems:

1. **MLflow** for experiment tracking
2. **FastAPI** for model serving
3. **Docker** for containerization
4. **CI/CD** for automation

```bash
# Switch to the complete MLOps version
git checkout main
```

## ğŸ“š What You'll Learn in Main Branch

- âœ… Experiment tracking with MLflow
- âœ… Model versioning and registry
- âœ… REST API with FastAPI
- âœ… Docker containerization
- âœ… Automated testing
- âœ… CI/CD pipeline with GitHub Actions
- âœ… Production-ready deployment

---

**This branch is intentionally simple to show why MLOps is necessary!**
